{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImages(arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20, 20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(arr, axes):\n",
    "        ax.imshow(img)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "validate_dir = os.path.join(data_dir, 'validation')\n",
    "\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "validate_dogs_dir = os.path.join(validate_dir, 'dogs')\n",
    "validate_cats_dir = os.path.join(validate_dir, 'cats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dogs_train = len(os.listdir(train_dogs_dir))\n",
    "num_cats_train = len(os.listdir(train_cats_dir))\n",
    "num_dogs_validate = len(os.listdir(validate_dogs_dir))\n",
    "num_cats_validate = len(os.listdir(validate_cats_dir))\n",
    "\n",
    "train_total = num_dogs_train + num_cats_train\n",
    "validate_total = num_dogs_validate + num_cats_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 150\n",
    "\n",
    "# data normalisation\n",
    "img_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_img_gen = img_gen.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                           directory=train_dir,\n",
    "                                           shuffle=True,\n",
    "                                           target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                           class_mode='binary')\n",
    "\n",
    "validate_img_gen = img_gen.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                               directory=validate_dir,\n",
    "                                               shuffle=False,\n",
    "                                               target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                               class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showImages([train_img_gen[0][0][0] for i in range(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 72, 72, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 34, 34, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               1605888   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,846,977\n",
      "Trainable params: 1,846,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3))) # 32\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3))) # 32\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3))) # 64\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3))) # none\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256)) # 64\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1)) # check 1 for sigmoid or 2 for softmax\n",
    "model.add(Activation('sigmoid')) # check also sigmoid or softmax\n",
    "\n",
    "model.compile(loss='binary_crossentropy', # binary_crossentropy\n",
    "              optimizer='rmsprop', # rmsprop or adam\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "626/626 [==============================] - 1951s 3s/step - loss: 0.6455 - accuracy: 0.6165 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
      "Epoch 2/5\n",
      "626/626 [==============================] - 4861s 8s/step - loss: 0.4918 - accuracy: 0.7677 - val_loss: 0.4433 - val_accuracy: 0.7922\n",
      "Epoch 3/5\n",
      "626/626 [==============================] - 3532s 6s/step - loss: 0.4052 - accuracy: 0.8163 - val_loss: 0.3849 - val_accuracy: 0.8210\n",
      "Epoch 4/5\n",
      "626/626 [==============================] - 6366s 10s/step - loss: 0.3464 - accuracy: 0.8517 - val_loss: 0.3159 - val_accuracy: 0.8662\n",
      "Epoch 5/5\n",
      "626/626 [==============================] - 4450s 7s/step - loss: 0.3029 - accuracy: 0.8729 - val_loss: 0.2884 - val_accuracy: 0.8792\n"
     ]
    }
   ],
   "source": [
    "fit_result = model.fit_generator(\n",
    "            train_img_gen,\n",
    "            steps_per_epoch=int(np.ceil(train_total / float(BATCH_SIZE))),\n",
    "            epochs=5, \n",
    "            validation_data=validate_img_gen,\n",
    "            validation_steps=int(np.ceil(validate_total / float(BATCH_SIZE)))\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61651355, 0.7676717, 0.81634384, 0.8517372, 0.87290335]\n"
     ]
    }
   ],
   "source": [
    "print(fit_result.history['accuracy'])\n",
    "# model-small [0.6479633, 0.76248, 0.7983227, 0.82098645, 0.8321685]\n",
    "# model-big [0.61651355, 0.7676717, 0.81634384, 0.8517372, 0.87290335]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model-big.h5')\n",
    "# model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "# make a prediction for a new image.\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "\n",
    "# load and prepare the image\n",
    "def load_image(filename):\n",
    "\t# load the image\n",
    "\timg = load_img(filename, target_size=(150, 150))\n",
    "\t# convert to array\n",
    "\timg = img_to_array(img)\n",
    "\t# reshape into a single sample with 3 channels\n",
    "\timg = img.reshape(1, 150, 150, 3)\n",
    "\t# center pixel data\n",
    "\timg = img.astype('float32')\n",
    "\timg = img - [123.68, 116.779, 103.939]\n",
    "\treturn img\n",
    "\n",
    "# load an image and predict the class\n",
    "def run_example():\n",
    "\t# load the image\n",
    "\timg = load_image('data/validation/cats/cat.10074.jpg')\n",
    "\t# load model\n",
    "\t#model = load_model('model-big.h5')\n",
    "\t# predict the class\n",
    "\tresult = model.predict(img)\n",
    "\tprint(result[0])\n",
    "\n",
    "# entry point, run the example\n",
    "run_example()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
